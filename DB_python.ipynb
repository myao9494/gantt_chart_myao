{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bca54bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, DATETIME\n",
    "from sqlalchemy.dialects.mysql import insert\n",
    "import pandas as pd\n",
    "# import utility\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "sys.path.append(\"../mylib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8addc640",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class db_con(object):\n",
    "    '''\n",
    "    pythonからmysqlのDBへアクセスする\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        pd.set_option(\"display.max_colwidth\", 10000)\n",
    "        pd.set_option('display.max_rows', 500)\n",
    "        self.user = \"root\"\n",
    "        self.password = \"\"\n",
    "        self.host = \"localhost\"\n",
    "        self.port = 3306\n",
    "        self.database_1 = \"gantt_howto_node\"\n",
    "        self.url_1 = f'mysql+pymysql://{self.user}:{self.password}@{self.host}:{self.port}/{self.database_1}?charset=utf8'\n",
    "        self.engine_1 = create_engine(self.url_1, echo=False)\n",
    "\n",
    "    def create_db(self):\n",
    "        query = \"select * from gantt_tasks\"\n",
    "        self.df = pd.read_sql(query, con=self.engine_1)\n",
    "        return self.df\n",
    "\n",
    "    def move_task(self, taisho_start, nobasu_day):\n",
    "        #         if not hasattr(self,\"df\"):\n",
    "        self.create_db()\n",
    "        df_taisho = self.df.copy()\n",
    "        df_taisho = df_taisho[df_taisho[\"start_date\"] == taisho_start]\n",
    "        df_taisho = df_taisho[df_taisho[\"progress\"] < 1]\n",
    "        df_taisho[\"start_date\"] = df_taisho[\"start_date\"] + \\\n",
    "            pd.Timedelta(days=nobasu_day)\n",
    "        out = self.to_db(df_taisho, \"start_date\")\n",
    "        print(out)\n",
    "        # 文字列から日付オブジェクトに変換\n",
    "        taisho_start_date = datetime.strptime(taisho_start, \"%Y-%m-%d\")\n",
    "        # 日数を加算\n",
    "        extended_date = taisho_start_date + timedelta(days=nobasu_day)\n",
    "        # 結果を表示\n",
    "        print(extended_date.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    def to_db(self, df_taisho, retu_mei):\n",
    "        if len(df_taisho) != 0:\n",
    "            metadata_1 = MetaData()\n",
    "            metadata_1.bind = self.engine_1\n",
    "            menus = Table(\n",
    "                'gantt_tasks', metadata_1,\n",
    "                Column('id', Integer, primary_key=True),\n",
    "                Column(retu_mei, DATETIME),\n",
    "            )\n",
    "\n",
    "            conn = self.engine_1.connect()\n",
    "\n",
    "            for index in range(len(df_taisho)):\n",
    "                rec = df_taisho.iloc[index:index +\n",
    "                                     1][[\"id\", retu_mei]].to_dict(\"records\")\n",
    "                insert_stmt = insert(menus).values(rec)\n",
    "                # on_duplicate_key_stmt = insert_stmt.on_duplicate_key_update(\n",
    "                #     start_date=insert_stmt.inserted.start_date\n",
    "                # )\n",
    "                command = f\"conn.execute(insert_stmt.on_duplicate_key_update({retu_mei}=insert_stmt.inserted.{retu_mei}))\"\n",
    "                exec(command)\n",
    "#                 print(index,rec)\n",
    "            conn.close()\n",
    "            out = f\"{len(df_taisho)}件処理しました\"\n",
    "        else:\n",
    "            out = \"０件でした\"\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13b2dcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        get_ipython\n",
    "        print(\"ss\")\n",
    "        obj = db_con()\n",
    "        taisho_start = \"2024-2-19\"\n",
    "        nobasu_day = 7\n",
    "    except NameError:\n",
    "        print(\"このコードはJupyter Notebook外で実行されています。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b216b",
   "metadata": {},
   "source": [
    "# factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8639240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_from_db(db_config: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    データベースからgantt_tasksテーブルのデータを読み込み、データフレームとして返します。\n",
    "\n",
    "    Args:\n",
    "    - db_config (dict): データベース接続の詳細。キーにはhost, port, user, password, databaseが含まれます。\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: gantt_tasksテーブルのデータを含むデータフレーム。\n",
    "    \"\"\"\n",
    "    # SQLAlchemyエンジンを作成\n",
    "    engine = create_engine(\n",
    "        f\"mysql+mysqlconnector://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\")\n",
    "    # データベースからデータを読み込む\n",
    "    df = pd.read_sql(\"SELECT * FROM gantt_tasks\", engine)\n",
    "    return df\n",
    "\n",
    "\n",
    "def write_to_db(df: pd.DataFrame, db_config: dict) -> None:\n",
    "    \"\"\"\n",
    "    指定されたデータフレームをデータベースのgantt_tasksテーブルに書き込みます。あ\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): 書き込みたいデータを含むデータフレーム。\n",
    "    - db_config (dict): データベース接続の詳細。キーにはhost, port, user, password, databaseが含まれます。\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # SQLAlchemyエンジンを作成\n",
    "    engine = create_engine(\n",
    "        f\"mysql+mysqlconnector://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\")\n",
    "    # データフレームをデータベースに書き込む\n",
    "    df.to_sql('gantt_tasks', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a78cd88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_relationship_id_using_text(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    データフレームから親子関係のIDを生成する関数（text列を使用）。\n",
    "\n",
    "    Parameters:\n",
    "    - df: pd.DataFrame\n",
    "        'text'と'parent'の列を持つデータフレーム。\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame\n",
    "        元のデータフレームに'relationship_id'の列が追加されたデータフレーム。\n",
    "    \"\"\"\n",
    "\n",
    "    def get_path(text, relationships, df):\n",
    "        \"\"\"タスクのtextから親へのパスを取得\"\"\"\n",
    "        path = [text]\n",
    "        task_id = df[df['text'] == text]['id'].values[0]\n",
    "        while relationships[task_id]['parent'] is not None:\n",
    "            parent_id = relationships[task_id]['parent']\n",
    "            parent_text = df[df['id'] == parent_id]['text'].values[0]\n",
    "            path.insert(0, parent_text)\n",
    "            task_id = parent_id\n",
    "        return path\n",
    "\n",
    "    # 親子関係を格納する辞書を初期化\n",
    "    relationships = {}\n",
    "    for _, row in df.iterrows():\n",
    "        task_id = row['id']\n",
    "        parent_id = row['parent']\n",
    "        if parent_id == 0:\n",
    "            relationships[task_id] = {'parent': None, 'children': []}\n",
    "        else:\n",
    "            if parent_id not in relationships:\n",
    "                relationships[parent_id] = {\n",
    "                    'parent': None, 'children': [task_id]}\n",
    "            else:\n",
    "                relationships[parent_id]['children'].append(task_id)\n",
    "            relationships[task_id] = {'parent': parent_id, 'children': []}\n",
    "\n",
    "    # \"___\"を使って親子関係のパスを構築\n",
    "    df['relationship_id'] = df.apply(lambda row: '___'.join(\n",
    "        get_path(row['text'], relationships, df)), axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_to_str(val):\n",
    "    \"\"\"値を文字列に変換\n",
    "\n",
    "    Args:\n",
    "        val (Any): 変換する値\n",
    "\n",
    "    Returns:\n",
    "        str: 変換後の文字列\n",
    "    \"\"\"\n",
    "    if pd.isnull(val) or val == \"\":  # NaN, NaT, または空の文字列の場合\n",
    "        return 'NaN'\n",
    "\n",
    "    # 値が数値の場合の変換\n",
    "    if isinstance(val, (int, float)):\n",
    "        if val == int(val):  # 浮動小数点数が整数の場合\n",
    "            return str(int(val))\n",
    "        return str(val)\n",
    "\n",
    "    # datetime64[ns]タイプまたは文字列が日時フォーマットに見える場合\n",
    "    if isinstance(val, pd.Timestamp) or (isinstance(val, str) and (\"T\" in val and \"Z\" in val or \" \" in val and \":\" in val)):\n",
    "        try:\n",
    "            # ISOフォーマットや\"2024-03-27 0:00:00\" のようなフォーマットも正しく処理される\n",
    "            return pd.to_datetime(val).strftime('%Y-%m-%d')\n",
    "        except:\n",
    "            return str(val)  # 有効な日時形式でない場合はそのままの文字列を返す\n",
    "\n",
    "    return str(val)\n",
    "\n",
    "\n",
    "def compare_dataframes(df1, df2, index_col=\"\", df_name=[]):\n",
    "    \"\"\"\n",
    "    2つのデータフレームを比較し、更新された行、追加された行、削除されるべき行を識別します。\n",
    "    さらに、2つのデータフレーム間で共通および非共通の列に関する情報も出力します。\n",
    "\n",
    "    Args:\n",
    "    df1 (pd.DataFrame): 比較の基準となるデータフレーム\n",
    "    df2 (pd.DataFrame): 比較されるデータフレーム\n",
    "    df_name (list of str, optional): 'self'と'other'を置き換えるためのデータフレームの名前。デフォルトは空のリスト。\n",
    "\n",
    "    Returns:\n",
    "    df_common_updated (pd.DataFrame): df1にこれをupdateするとdf2になる(共通部分)\n",
    "    added_df (pd.DataFrame): df2で新たに追加された行(df1にこれを足せばdf2になる(非共通部分))\n",
    "    to_delete_df (pd.DataFrame): df1で存在し、df2で削除された行(df1からこれを消せばdf2になる(非共通部分))\n",
    "    df_diff (pd.DataFrame): df1とdf2の間で差異がある行の情報\n",
    "    common_col (Index): df1とdf2の共通の列の名前\n",
    "    col_diff (tuple): df1とdf2で非共通の列の名前 (df1のみの列, df2のみの列)\n",
    "    \"\"\"\n",
    "\n",
    "    # indexの指定があれば、index列のデータ型を統一してからindexとして設定する\n",
    "    if index_col != \"\":\n",
    "        # データ型を文字列に統一\n",
    "        df1[index_col] = df1[index_col].astype(str)\n",
    "        df2[index_col] = df2[index_col].astype(str)\n",
    "\n",
    "        # indexとして設定\n",
    "        df1 = df1.set_index(index_col, drop=False)\n",
    "        df2 = df2.set_index(index_col, drop=False)\n",
    "\n",
    "    # 共通の列のみ抽出\n",
    "    common_col = df1.columns.intersection(df2.columns)\n",
    "    non_common_columns_df1 = df1.columns.difference(df2.columns)\n",
    "    non_common_columns_df2 = df2.columns.difference(df1.columns)\n",
    "\n",
    "    df1_common = df1[common_col]\n",
    "    df2_common = df2[common_col]\n",
    "\n",
    "    # 各要素をconvert_to_str関数を使用して文字列に変換\n",
    "    df1_common = df1_common.applymap(convert_to_str)\n",
    "    df2_common = df2_common.applymap(convert_to_str)\n",
    "\n",
    "    # df2の中でdf1にないインデックスを見つけ、その行をadded_dfとする\n",
    "    added_df = df2.loc[df2.index.difference(df1.index)]\n",
    "\n",
    "    # df1の中でdf2にないインデックスを見つけ、その行をto_delete_dfとする\n",
    "    to_delete_df = df1.loc[df1.index.difference(df2.index)]\n",
    "\n",
    "    # df1とdf2の両方に存在するインデックスを持つ行を見つける\n",
    "    df1_common_index = df1_common.loc[df1_common.index.intersection(\n",
    "        df2_common.index)]\n",
    "    df2_common_index = df2_common.loc[df2_common.index.intersection(\n",
    "        df1_common.index)]\n",
    "\n",
    "    # df1_commonの中でdf2_commonと異なる部分を更新\n",
    "    df_out = df1.copy()\n",
    "    df_out.update(df2_common_index)\n",
    "\n",
    "    df_common_updated = df_out.copy()\n",
    "    df_diff = df1_common_index.sort_index()[list(\n",
    "        df2_common_index.columns)].compare(df2_common_index.sort_index())\n",
    "    col_diff = (non_common_columns_df1, non_common_columns_df2)\n",
    "\n",
    "    if len(df_name) == 2:\n",
    "        df_diff.columns = df_diff.columns.set_levels(df_diff.columns.levels[1].str.replace(\n",
    "            'self', df_name[0]).str.replace('other', df_name[1]), level=1)\n",
    "\n",
    "    return df_common_updated, added_df, to_delete_df, df_diff, common_col, col_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "922f659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_js_object_from_html_as_dict(html_path: str, keyword: str) -> dict:\n",
    "    \"\"\"\n",
    "    HTMLファイルから指定されたキーワードのJavaScriptオブジェクトを抽出して、Pythonの辞書として返す関数。\n",
    "\n",
    "    Parameters:\n",
    "    - html_path: str\n",
    "        HTMLファイルのパス。\n",
    "    - keyword: str\n",
    "        抽出したいJavaScriptオブジェクトのキーワード。\n",
    "\n",
    "    Returns:\n",
    "    - dict\n",
    "        抽出されたオブジェクトをPythonの辞書として返す。\n",
    "    \"\"\"\n",
    "\n",
    "    # HTMLファイルを読み込む\n",
    "    with open(html_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "    # スクリプトタグの中から指定されたキーワードを検索\n",
    "    script_content = None\n",
    "    for script in soup.find_all('script'):\n",
    "        if script.string and keyword in script.string:\n",
    "            script_content = script.string\n",
    "            break\n",
    "\n",
    "    if not script_content:\n",
    "        return {}\n",
    "\n",
    "    # 指定されたキーワードの部分を正規表現で抽出\n",
    "    pattern = rf'{re.escape(keyword)}\\s*=\\s*(\\[.*?\\]);'\n",
    "    match = re.search(pattern, script_content, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        #         print(match.group(1))\n",
    "        obj_string = match.group(1)\n",
    "        # キーをクォートで囲む\n",
    "        obj_string_quoted = re.sub(r'(\\w+):', r'\"\\1\":', obj_string)\n",
    "        # Pythonの辞書として読み込む\n",
    "        result_list = eval(obj_string_quoted)\n",
    "#         print(result_list)\n",
    "        # 指定された形式の辞書に変換\n",
    "        result_dict = {str(item['key']): item['label'] for item in result_list}\n",
    "    else:\n",
    "        result_dict = {}\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ee3a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self = db_con()\n",
    "\n",
    "# # 関数を使用してrelationship_idを生成\n",
    "# df = self.create_db()\n",
    "# df_moto = df.copy()\n",
    "# db_col = df.columns\n",
    "# original_dtypes = df.dtypes\n",
    "\n",
    "# result_df_text = generate_relationship_id_using_text(df)\n",
    "\n",
    "# # 'relationship_id' 列を使用してソート\n",
    "# sorted_df = result_df_text.sort_values(by='relationship_id')\n",
    "# # 関数をテスト\n",
    "# owner_dict = extract_js_object_from_html_as_dict(\n",
    "#     'public/index.html', 'gantt.owners')\n",
    "# #  担当者をIDから\n",
    "# sorted_df[\"担当者\"] = sorted_df[\"owner_id\"].map(owner_dict)\n",
    "\n",
    "\n",
    "# # \"___\"の数を数える\n",
    "# num_underscores = sorted_df['relationship_id'].str.count(\"___\")\n",
    "\n",
    "# num_col = []\n",
    "# # \"___\"の数に応じて新しい列にxを入れる\n",
    "\n",
    "# for i in range(1, num_underscores.max() + 2):\n",
    "#     col_name = str(i)\n",
    "#     num_col.append(col_name)\n",
    "#     sorted_df[col_name] = num_underscores.apply(\n",
    "#         lambda x: 'x' if x == i - 1 else '')\n",
    "\n",
    "# col_name\n",
    "\n",
    "# sorted_df.columns\n",
    "\n",
    "# a = [\"text\"]\n",
    "\n",
    "# a.extend(num_col)\n",
    "# a.extend(['start_date', 'duration', 'progress', 'kind_task',\n",
    "#          'memo', 'color', 'textColor', '担当者', 'hyperlink'])\n",
    "\n",
    "# sorted_df[a]\n",
    "\n",
    "# テストデータ追加\n",
    "\n",
    "# sorted_df = sorted_df.reset_index(drop=True)\n",
    "\n",
    "# # # 85と104の間に行を追加するためのインデックスを取得\n",
    "# index_85 = sorted_df.index[sorted_df['id'] == 147].tolist()[0]\n",
    "# # index_104 = sorted_df.index[sorted_df['id'] == 208].tolist()[0]\n",
    "\n",
    "# # 新しい行を作成し、textと3列のみ値を設定\n",
    "# new_row = pd.Series(index=sorted_df.columns)\n",
    "# new_row['text'] = 'テスト'\n",
    "# new_row['3'] = 'x'\n",
    "\n",
    "# # ID 85 と 104 の間の新しい行を削除\n",
    "# # sorted_df = sorted_df.drop(index_104)\n",
    "\n",
    "# # 新しい行を追加\n",
    "# sorted_df = pd.concat([sorted_df.iloc[:index_85+1], new_row.to_frame().T,\n",
    "#                       sorted_df.iloc[index_85+1:]]).reset_index(drop=True)\n",
    "\n",
    "# sorted_df.iloc[index_85-1:index_85+3]  # 対象の範囲を表示して確認\n",
    "\n",
    "# # id 列がNaNの行を新しく追加された行として識別\n",
    "# new_rows = sorted_df[sorted_df['id'].isna()]\n",
    "\n",
    "# # id 列のデータ型を数値に変換\n",
    "# sorted_df['id'] = pd.to_numeric(sorted_df['id'], errors='coerce')\n",
    "\n",
    "# # 新しい行の parent と relationship_id を設定\n",
    "# new_rows = sorted_df[sorted_df['id'].isna()]\n",
    "\n",
    "# # 今日の日付を取得\n",
    "# today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# for idx, row in new_rows.iterrows():\n",
    "#     # 新しい行のxが位置する列の番号-1を取得\n",
    "#     x_position = int(row[row == 'x'].index[0])\n",
    "#     parent_position = x_position - 1\n",
    "\n",
    "#     # その列にxが設定されている最も近い上の行を探す\n",
    "#     parent_index = sorted_df.iloc[:idx][sorted_df[str(\n",
    "#         parent_position)] == 'x'].index[-1]\n",
    "#     parent_row = sorted_df.iloc[parent_index]\n",
    "\n",
    "#     # その行のidとrelationship_idを新しい行のparentとrelationship_idに設定\n",
    "#     sorted_df.at[idx, 'parent'] = parent_row['id']\n",
    "#     sorted_df.at[idx, 'relationship_id'] = parent_row['relationship_id'] + \\\n",
    "#         '___' + row['text']\n",
    "\n",
    "#     # 新しい行にルールに従って値を設定\n",
    "#     sorted_df.loc[sorted_df['id'].isna(\n",
    "#     ), 'start_date'] = sorted_df['start_date'].fillna(today)\n",
    "#     sorted_df.loc[sorted_df['id'].isna(\n",
    "#     ), 'duration'] = sorted_df['duration'].fillna(1)\n",
    "#     sorted_df.loc[sorted_df['id'].isna(\n",
    "#     ), 'progress'] = sorted_df['progress'].fillna(0)\n",
    "#     sorted_df.loc[sorted_df['id'].isna(\n",
    "#     ), 'kind_task'] = sorted_df['kind_task'].fillna(1)\n",
    "\n",
    "#     # id の最大値を取得して、新しい行の 'id' 列に max_id + 1 を設定\n",
    "#     max_id = sorted_df['id'].max()\n",
    "#     sorted_df.at[idx, 'id'] = max_id + 1\n",
    "#     max_sortorder = sorted_df['sortorder'].max()\n",
    "#     sorted_df.at[idx, 'sortorder'] = max_sortorder + 1\n",
    "\n",
    "# sorted_df = sorted_df.fillna(\"\")\n",
    "\n",
    "# sorted_df[sorted_df['id'] > max_id - len(new_rows)]  # 新しい行の確認\n",
    "\n",
    "# sorted_df.to_clipboard()\n",
    "\n",
    "# # 結果を確認\n",
    "# sorted_df = sorted_df.astype(original_dtypes)\n",
    "\n",
    "# df_common_updated, added_df, to_delete_df, df_diff, common_col, col_diff = compare_dataframes(\n",
    "#     df_moto, sorted_df, \"id\")\n",
    "\n",
    "# added_df\n",
    "\n",
    "# to_delete_df\n",
    "\n",
    "# df_diff\n",
    "\n",
    "# db_config = {\n",
    "#     \"host\": \"localhost\",\n",
    "#     \"port\": 3306,  # default MySQL port\n",
    "#     \"user\": \"root\",\n",
    "#     \"password\": \"\",\n",
    "#     \"database\": \"gantt_howto_node\"\n",
    "# }\n",
    "\n",
    "# write_to_db(sorted_df[db_col], db_config)\n",
    "\n",
    "# ## スケジュール\n",
    "\n",
    "# def extract_schedule_with_text_from_df_v3(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     DataFrameからtask_scheduleとtextカラムを抽出し、テーブル形式に変換する関数 (さらに修正版)\n",
    "\n",
    "#     Args:\n",
    "#     - df (pd.DataFrame): 入力のDataFrame\n",
    "\n",
    "#     Returns:\n",
    "#     - pd.DataFrame: 変換したテーブル形式のDataFrame\n",
    "#     \"\"\"\n",
    "\n",
    "#     def convert_task_schedule(row):\n",
    "#         items = str(row['task_schedule']).split('___')\n",
    "#         records = []\n",
    "#         for item in items:\n",
    "#             parts = item.split(',')\n",
    "#             if len(parts) >= 3:\n",
    "#                 records.append({\n",
    "#                     'original_id': row['id'],\n",
    "#                     'pro_or_task': row['text'],\n",
    "#                     'description': parts[1],\n",
    "#                     'start_date': parts[0],\n",
    "#                     'duration[days]': parts[2],\n",
    "#                 })\n",
    "#         return records\n",
    "\n",
    "#     extracted_data = df.apply(convert_task_schedule, axis=1)\n",
    "#     flat_data = [item for sublist in extracted_data for item in sublist]\n",
    "\n",
    "#     return pd.DataFrame(flat_data)\n",
    "\n",
    "\n",
    "# # テスト\n",
    "# extracted_schedule_with_text_df_v3 = extract_schedule_with_text_from_df_v3(df)\n",
    "# extracted_schedule_with_text_df_v3\n",
    "\n",
    "# def update_original_df_with_text_v3(original_df: pd.DataFrame, edited_schedule_df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     編集後のテーブル形式のデータ（text列を含む）をもとに、オリジナルのDataFrameに変更を反映する関数 (さらに修正版)\n",
    "\n",
    "#     Args:\n",
    "#     - original_df (pd.DataFrame): オリジナルのDataFrame\n",
    "#     - edited_schedule_df (pd.DataFrame): 編集後のテーブル形式のデータ\n",
    "\n",
    "#     Returns:\n",
    "#     - pd.DataFrame: 更新されたDataFrame\n",
    "#     \"\"\"\n",
    "\n",
    "#     # start_dateのフォーマットを確認・修正する関数\n",
    "#     def format_date(date_str):\n",
    "#         try:\n",
    "#             return pd.to_datetime(date_str).strftime('%Y-%m-%d')\n",
    "#         except:\n",
    "#             return date_str  # フォーマットできない場合はそのまま返す\n",
    "\n",
    "#     edited_schedule_df['start_date'] = edited_schedule_df['start_date'].apply(\n",
    "#         format_date)\n",
    "\n",
    "#     # original_idでgroupbyして文字列を再構築\n",
    "#     def rebuild_task_schedule(group):\n",
    "#         return '___'.join([f\"{row['start_date']},{row['description']},{row['duration[days]']}\" for _, row in group.iterrows()])\n",
    "\n",
    "#     new_task_schedule = edited_schedule_df.groupby(\n",
    "#         'original_id').apply(rebuild_task_schedule)\n",
    "\n",
    "#     # オリジナルのDataFrameを更新\n",
    "#     updated_df = original_df.copy()\n",
    "#     updated_df['task_schedule'] = updated_df['id'].map(new_task_schedule)\n",
    "\n",
    "#     return updated_df\n",
    "\n",
    "\n",
    "# # テスト\n",
    "# # ここでは変換したデータをそのまま「編集後」として扱う\n",
    "# edited_schedule_with_text_df_v3 = extracted_schedule_with_text_df_v3.copy()\n",
    "# updated_df_with_text_v3 = update_original_df_with_text_v3(\n",
    "#     df, edited_schedule_with_text_df_v3)\n",
    "# updated_df_with_text_v3[['id', 'text', 'task_schedule']]\n",
    "\n",
    "\n",
    "# ! code .\n",
    "\n",
    "# ## test\n",
    "\n",
    "# df_taisho = pd.DataFrame([{'id': 107, 'task_schedule': '2022-7-22,上西内科,1,___'}\n",
    "#                           ])\n",
    "\n",
    "# df_taisho\n",
    "\n",
    "# # self = db_con()\n",
    "\n",
    "# # # self.create_db()\n",
    "\n",
    "# # taisho_start = \"2022-07-11\"\n",
    "# # nobasu_day = -7\n",
    "# # self.move_task(taisho_start,nobasu_day)\n",
    "\n",
    "# retu_mei = \"task_schedule\"\n",
    "\n",
    "# metadata_1 = MetaData()\n",
    "# metadata_1.bind = self.engine_1\n",
    "# menus = Table(\n",
    "#     'gantt_tasks', metadata_1,\n",
    "#     Column('id', Integer, primary_key=True),\n",
    "#     Column(retu_mei, DATETIME),\n",
    "# )\n",
    "\n",
    "# conn = self.engine_1.connect()\n",
    "\n",
    "# rec = df_taisho.iloc[index:index+1][[\"id\", retu_mei]].to_dict(\"records\")\n",
    "# insert_stmt = insert(menus).values(rec)\n",
    "\n",
    "# command = f\"on_duplicate_key_stmt = insert_stmt.on_duplicate_key_update({retu_mei}=insert_stmt.inserted.{retu_mei})\"\n",
    "\n",
    "# exec(command)\n",
    "\n",
    "# conn.execute(on_duplicate_key_stmt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
